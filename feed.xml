<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://hoangmgh.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://hoangmgh.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-12-18T20:51:29+00:00</updated><id>https://hoangmgh.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">üìà üåêVisualizing your WGCNA result</title><link href="https://hoangmgh.github.io/blog/2023/WGCNA-vis/" rel="alternate" type="text/html" title="üìà üåêVisualizing your WGCNA result"/><published>2023-12-11T10:25:00+00:00</published><updated>2023-12-11T10:25:00+00:00</updated><id>https://hoangmgh.github.io/blog/2023/WGCNA-vis</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2023/WGCNA-vis/"><![CDATA[<p><strong>1. Volcano plot</strong></p> <p>After the construction of gene network modules with WGCNA, I guess one would be left with the question: what‚Äôs next? As a no-brainer step, one can screen for interesting modules that correlate with clinical features of interest. For example, I have seen people using the following heatmap to summarize the result of correlating modules with multiple clinical features:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/wgcna_heatmap-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/wgcna_heatmap-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/wgcna_heatmap-1400.webp"/> <img src="/assets/img/wgcna_heatmap.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lineage dotplot" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A heatmap showing the correlation of different module's eigengenes and features of interest </div> <p>However, for someone who would want to construct multiple modules from various cell-type, one can end up with a lot of network modules. In this case, a volcano plot might be useful to summarize the result of correlation between hundreds of modules and only a few variables (2-3 variables). For example, I identified quite a lot of module from just one population of epithelial cells obtained from scRNA-seq data alone:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/wgcna_volcano-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/wgcna_volcano-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/wgcna_volcano-1400.webp"/> <img src="/assets/img/wgcna_volcano.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lineage dotplot" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A Volcano plot showing the correlation coefficient of different module's eigengenes (x-axis) and features of interest and their corresponding p-value (y-axis) </div> <p>Of course, one can argue that the whole point of a volcano plot and a heatmap are very different. When you have a lot of clinical variables, a heatmap can be useful to highlight the bulk pattern of correlations between modules-variables as well as between variables. For only a few variable, a volcano plot might be more useful: we can do some more follow-up on the modules that pass a certain threshold for correlation.</p> <p><strong>2. Trend plot</strong></p> <p>One way to ‚ÄúQC‚Äù a gene module as well as visualizing its correlating pattern with a response variable is to, welp, plot all the gene expressions and the variable on the same plot. This might sound like a lot, especially when you have hundreds if not thousands of genes. One can do the following: select genes that have high module-memberships to the module, scale them to be between 0-1, and plot only those genes‚Äô expressions (log10 CPM) against the values of the response variable; simultaneously, plotting the mean trend of the module as well, e.g. eigengene. For example, in our study, we detect an interesting module that is tightly correlated with immune-infiltration:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/e5_example-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/e5_example-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/e5_example-1400.webp"/> <img src="/assets/img/e5_example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lineage dotplot" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A scatterplot showing the correlation between a gene module in Epithelial cells and immune infiltration </div> <p>You can also connect the dots with lines, so it will look more like a bunch of lines making up one overarching trend. It is quite interesting because the genes do look highly correlated to each other and to the mean-trend (the blue line). Simultaneously, the pattern is almost exponential. We actually detect these genes by correlating the log10 value of immune infiltration and the modules‚Äô eigengenes!</p> <p>From this experience, I also realize the importance of using Module‚Äôs mean gene, as opposed to module‚Äôs eigengene to represent the overall trend of a module, as suggested by the author. Obviously, these two values represent two different thing! the module‚Äôs mean gene might be useful as we are built on the assumption that most genes are very similar and ‚Äúwiggle‚Äù around a mean trend. The module‚Äôs eigengene simply is the PC1 of the genes, and not necessarily their mean, but a weighted sum of the genes that has the most variation.</p> <p><strong>3. Scatter plot</strong></p> <p>Another kind of plot you can use alongside with the trend plot is the basic scatterplot on a per gene basis. For example, here is the log10CPM of genes highly correlating with log10(immune infiltration):</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/wgcna_scatterplot-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/wgcna_scatterplot-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/wgcna_scatterplot-1400.webp"/> <img src="/assets/img/wgcna_scatterplot.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lineage dotplot" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A scatterplot showing the correlation between a gene module in Epithelial cells and immune infiltration </div> <p>It is important to report statistics such as the correlation coefficient, and one might also add a SE band for each gene!</p> <p><strong>4. Other thoughts</strong></p> <p>I think it is important to use other kind of measures for follow-up analyses on interesting modules. One doesn‚Äôt have to use module eigengenes to represent the overall trend of a module. One can simply average the scaled values of all the genes (scaling is important here due to different dynamic range):</p> <div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">moduleMeangenes</span><span class="o">=</span><span class="k">function</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span><span class="n">color</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">color</span><span class="p">)</span><span class="o">!=</span><span class="n">ncol</span><span class="p">(</span><span class="n">matrix</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">print</span><span class="p">(</span><span class="s2">"the size of color vector doesnt match matrix size"</span><span class="p">)</span><span class="w">
    </span><span class="p">}</span><span class="w">
     </span><span class="n">modules_genes</span><span class="o">=</span><span class="n">split</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="n">ncol</span><span class="p">(</span><span class="n">matrix</span><span class="p">),</span><span class="n">color</span><span class="p">)</span><span class="w">
     </span><span class="nf">names</span><span class="p">(</span><span class="n">modules_genes</span><span class="p">)</span><span class="o">=</span><span class="n">paste0</span><span class="p">(</span><span class="s2">"ME"</span><span class="p">,</span><span class="nf">names</span><span class="p">(</span><span class="n">modules_genes</span><span class="p">))</span><span class="w">
        
     </span><span class="nf">return</span><span class="p">(</span><span class="n">sapply</span><span class="p">(</span><span class="n">modules_genes</span><span class="p">,</span><span class="k">function</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="n">apply</span><span class="p">(</span><span class="n">scale</span><span class="p">(</span><span class="n">matrix</span><span class="p">[,</span><span class="n">i</span><span class="p">]),</span><span class="m">1</span><span class="p">,</span><span class="n">mean</span><span class="p">)))</span><span class="w">
    
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>here \(matrix\) would be a sample \(\times\) genes, and \(color\) would be a vector assigning a group to each gene.</p> <p>At the same time, one can decide to use Pearson \(\rho\), the Kendall correlation, or the Spearman correlation for screening interesting modules. Each is simply to answer a different kind of question.</p>]]></content><author><name></name></author><category term="Bioinformatics"/><category term="visualization"/><summary type="html"><![CDATA[Learn to visualize your network module in an intuitive way]]></summary></entry><entry><title type="html">üì¢ Genetic-demultiplexing with Souporcell - GPU implementation</title><link href="https://hoangmgh.github.io/blog/2023/souporcell-GPU/" rel="alternate" type="text/html" title="üì¢ Genetic-demultiplexing with Souporcell - GPU implementation"/><published>2023-11-15T00:00:00+00:00</published><updated>2023-11-15T00:00:00+00:00</updated><id>https://hoangmgh.github.io/blog/2023/souporcell-GPU</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2023/souporcell-GPU/"><![CDATA[<p>I rewrote souporcell so it can be run on GPU with half of the time required. This can be particularly useful if you need to tune parameters several times for an experiment</p> <p>Then the whole <a href="https://github.com/wheaton5/souporcell/blob/master/souporcell_pipeline.py">souporcell.py</a> can be broken down do three components: read_mtx(), cluster_step(). The cluster step can benefit from running on GPU. Basically we can replace <strong><em>tf.</em></strong> with <strong><em>tf.compat.v1</em></strong>, and run the Gradient Descent step with the with <strong><em>with tf.device(‚Äú/GPU:0‚Äù)</em></strong> : The first step is to read in the matrices (ref.mtx and alt.mtx), filter out loci that are expressed in at least \(min_{alt}\) and \(min_{ref}\) cells, and finally create a list of possible loci and their corresponding indices to be used. We call this the ‚Äúpool of indices‚Äù, from where we will go on to the cluster step and do more filtering:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">read_mtx</span><span class="p">(</span><span class="n">min_alt</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="n">min_ref</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="n">K</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span><span class="n">max_loci</span> <span class="o">=</span><span class="mi">1024</span><span class="p">,</span><span class="n">alt_matrix</span><span class="o">=</span><span class="sh">"</span><span class="s">alt_simulated.mtx</span><span class="sh">"</span><span class="p">,</span><span class="n">ref_matrix</span><span class="o">=</span><span class="sh">"</span><span class="s">ref_simulated.mtx</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">cell_index</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">total_lost</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loci_counts</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">cell_counts</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">alt_matrix</span><span class="p">)</span> <span class="k">as</span> <span class="n">alt</span><span class="p">:</span>
        <span class="n">alt</span><span class="p">.</span><span class="nf">readline</span><span class="p">()</span>
        <span class="n">alt</span><span class="p">.</span><span class="nf">readline</span><span class="p">()</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">alt</span><span class="p">.</span><span class="nf">readline</span><span class="p">().</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">()</span>
        <span class="n">cells</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">cell_counts</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">cells</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>
        <span class="n">total_loci</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">alt</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">()</span>
            <span class="n">locus</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">cell</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">cell_counts</span><span class="p">.</span><span class="nf">setdefault</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="p">{})</span>
            <span class="n">count</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">cell_counts</span><span class="p">[</span><span class="n">cell</span><span class="p">][</span><span class="n">locus</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">count</span><span class="p">]</span>
            <span class="n">loci_counts</span><span class="p">.</span><span class="nf">setdefault</span><span class="p">(</span><span class="n">locus</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">loci_counts</span><span class="p">[</span><span class="n">locus</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">ref_matrix</span><span class="p">)</span> <span class="k">as</span> <span class="n">alt</span><span class="p">:</span>
        <span class="n">alt</span><span class="p">.</span><span class="nf">readline</span><span class="p">()</span>
        <span class="n">alt</span><span class="p">.</span><span class="nf">readline</span><span class="p">()</span>
        <span class="n">alt</span><span class="p">.</span><span class="nf">readline</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">alt</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">()</span>
            <span class="n">locus</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">cell</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">count</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">cell_counts</span><span class="p">[</span><span class="n">cell</span><span class="p">][</span><span class="n">locus</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span>
            <span class="n">loci_counts</span><span class="p">.</span><span class="nf">setdefault</span><span class="p">(</span><span class="n">locus</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">loci_counts</span><span class="p">[</span><span class="n">locus</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">used_loci_set</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>
    <span class="n">used_loci</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="nf">for </span><span class="p">(</span><span class="n">locus</span><span class="p">,</span> <span class="n">counts</span><span class="p">)</span> <span class="ow">in</span> <span class="n">loci_counts</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">counts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_ref</span> <span class="ow">and</span> <span class="n">counts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_alt</span><span class="p">:</span>
            <span class="n">used_loci</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">locus</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">used_loci_set</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">locus</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">used_loci</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">used_loci</span><span class="p">)</span>
    <span class="n">used_loci_indices</span> <span class="o">=</span> <span class="p">{</span><span class="n">locus</span><span class="p">:</span><span class="n">i</span> <span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">locus</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">used_loci</span><span class="p">)}</span>
    <span class="n">loci</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">used_loci</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">used_loci_indices</span><span class="p">,</span><span class="n">used_loci_set</span><span class="p">,</span><span class="n">used_loci</span><span class="p">,</span><span class="n">loci</span><span class="p">,</span><span class="n">loci_counts</span><span class="p">,</span><span class="n">cell_counts</span>
</code></pre></div></div> <p>The next step is called the cluster step, where we build the fractional matrices for all cell. However, each cell will have their own set of loci and might not be overlapping with other sets from other cells. This is quite interesting! It is also important that one can use up to \(max_{loci}\) loci (default =1024). Regardless, the set of loci for each cell must satisfy:</p> <ul> <li>they must be pooled from the pool of cells identified earlier (used_loci_indices)</li> <li>the loci are considered if they are expressed in the given cell ( ref_count &gt; 0 and alt_count &gt; 0)</li> </ul> <p>I am adding a parameter for known_cells, where the indices of known cells and their corresponding cluster number must be provided (a dataframe) This works by assigning a maximal weight to the known cluster:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weightshape_np</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">broadcast_to</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="n">T</span><span class="p">,(</span><span class="n">K</span><span class="p">,</span><span class="n">max_loci</span><span class="p">,</span><span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))))</span>

   
        
    <span class="k">if</span> <span class="n">known_cells</span>  <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">known_cells</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span> <span class="o">&lt;=</span> <span class="n">K</span>
        <span class="k">assert</span> <span class="n">known_cells</span><span class="p">.</span><span class="n">columns</span><span class="o">==</span><span class="p">[</span><span class="sh">"</span><span class="s">index</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">cluster</span><span class="sh">"</span><span class="p">]</span>
        <span class="c1">#did a quick check for unique assignment to a cluster:
</span>        <span class="n">freq</span><span class="o">=</span><span class="n">known_cell</span><span class="p">[</span><span class="sh">"</span><span class="s">cluster</span><span class="sh">"</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">freq</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">known_cells</span><span class="p">.</span><span class="nf">keys</span><span class="p">()):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">k</span><span class="o">!=</span><span class="n">i</span><span class="p">:</span>
                    <span class="n">weightshape_np</span><span class="p">[</span><span class="n">known_cells</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,:,</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">weightshape_np</span><span class="p">[</span><span class="n">known_cells</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,:,</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="mi">10000</span>    
</code></pre></div></div> <p>and so the likelihood of seeing a known cell‚Äôs genotype vector is: \begin{equation} P(x=v_c) = e^{-\frac{1}{2}|v_c-\theta_k|} \end{equation} given that cell \(c\) is drawn from a Gaussian centered at \(\theta_k\) Instead of assigning the weights with 10000, perhaps there is a better way to represent ‚Äúmaximal distance‚Äù of \(v_c\) from other \(\theta_1\), \(\theta_2\),‚Ä¶ but not \(\theta_k\)‚Ä¶</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>


<span class="k">def</span> <span class="nf">cluster_step</span><span class="p">(</span><span class="n">max_loci</span><span class="p">,</span><span class="n">K</span><span class="p">,</span><span class="n">training_epochs</span><span class="p">,</span><span class="n">repeats</span><span class="p">,</span><span class="n">cell_counts</span><span class="p">,</span><span class="n">loci_counts</span><span class="p">,</span><span class="n">used_loci_indices</span><span class="p">,</span><span class="n">known_cells</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_ref</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">min_alt</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="p">.</span><span class="mi">1</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">loci being us based on min_alt, min_ref, and max_loci </span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">loci</span><span class="p">))</span>
    <span class="n">cells</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">cell_counts</span><span class="p">)</span>
    <span class="n">total_lost</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">cell_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">cells</span><span class="p">,</span> <span class="n">max_loci</span><span class="p">))</span>
    <span class="n">cell_loci</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">cells</span><span class="p">,</span> <span class="n">max_loci</span><span class="p">))</span>
    
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">cells</span><span class="p">,</span> <span class="n">max_loci</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">cell_counts</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
        <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">single_cell_counts</span> <span class="o">=</span> <span class="n">cell_counts</span><span class="p">[</span><span class="n">cell</span><span class="p">]</span>
        
        <span class="c1">#prioritize locus that is highly expressed across cells:
</span>        <span class="c1">#for this given cell, get the set of 
</span>        
        <span class="n">this_cell_locus</span><span class="o">=</span><span class="nf">list</span><span class="p">(</span><span class="n">cell_counts</span><span class="p">[</span><span class="n">cell</span><span class="p">].</span><span class="nf">keys</span><span class="p">())</span>
       
             
        <span class="k">for</span> <span class="n">locus</span> <span class="ow">in</span> <span class="n">this_cell_locus</span><span class="p">:</span>
            <span class="n">locus_counts</span> <span class="o">=</span> <span class="n">single_cell_counts</span><span class="p">[</span><span class="n">locus</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">loci_counts</span><span class="p">[</span><span class="n">locus</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_ref</span> <span class="ow">and</span> <span class="n">loci_counts</span><span class="p">[</span><span class="n">locus</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_alt</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">index</span> <span class="o">&lt;</span> <span class="n">max_loci</span><span class="p">:</span>
                    <span class="n">ref_c</span> <span class="o">=</span> <span class="n">locus_counts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">alt_c</span> <span class="o">=</span> <span class="n">locus_counts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">ref_c</span> <span class="o">+</span> <span class="n">alt_c</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">cell_data</span><span class="p">[</span><span class="n">cell</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">ref_c</span><span class="p">)</span><span class="o">/</span><span class="nf">float</span><span class="p">(</span><span class="n">ref_c</span> <span class="o">+</span> <span class="n">alt_c</span><span class="p">)</span> <span class="k">if</span> <span class="n">ref_c</span> <span class="o">+</span> <span class="n">alt_c</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>
                        <span class="n">cell_loci</span><span class="p">[</span><span class="n">cell</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">used_loci_indices</span><span class="p">[</span><span class="n">locus</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                        <span class="n">weights</span><span class="p">[</span><span class="n">cell</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
                        <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">total_lost</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1">### set 0 weights for cells from other clusters:
</span>    <span class="n">random_size</span><span class="o">=</span><span class="mi">100</span>


    <span class="n">data</span> <span class="o">=</span> <span class="n">cell_data</span>
    <span class="n">data_loci</span> <span class="o">=</span> <span class="n">cell_loci</span>
    <span class="n">weightshape_np</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">broadcast_to</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="n">T</span><span class="p">,(</span><span class="n">K</span><span class="p">,</span><span class="n">max_loci</span><span class="p">,</span><span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))))</span>

   
        
    <span class="k">if</span> <span class="n">known_cells</span>  <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">known_cells</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span> <span class="o">&lt;=</span> <span class="n">K</span>
        <span class="k">assert</span> <span class="n">known_cells</span><span class="p">.</span><span class="n">columns</span><span class="o">==</span><span class="p">[</span><span class="sh">"</span><span class="s">index</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">cluster</span><span class="sh">"</span><span class="p">]</span>
        <span class="c1">#did a quick check for unique assignment to a cluster:
</span>        <span class="n">freq</span><span class="o">=</span><span class="n">known_cell</span><span class="p">[</span><span class="sh">"</span><span class="s">cluster</span><span class="sh">"</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">freq</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">known_cells</span><span class="p">.</span><span class="nf">keys</span><span class="p">()):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">k</span><span class="o">!=</span><span class="n">i</span><span class="p">:</span>
                    <span class="n">weightshape_np</span><span class="p">[</span><span class="n">known_cells</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,:,</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">weightshape_np</span><span class="p">[</span><span class="n">known_cells</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,:,</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="mi">10000</span>    
    
    <span class="n">cells</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1">#save this for investigation:
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">save cell_data and cell_loci:</span><span class="sh">"</span><span class="p">)</span>
     
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span>
    
    
    <span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
    
    <span class="n">session_conf</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nc">ConfigProto</span><span class="p">(</span>
          <span class="n">allow_soft_placement</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">session_conf</span><span class="p">.</span><span class="n">gpu_options</span><span class="p">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">session_conf</span><span class="p">.</span><span class="n">gpu_options</span><span class="p">.</span><span class="n">per_process_gpu_memory_fraction</span> <span class="o">=</span><span class="mi">1</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">disable_eager_execution</span><span class="p">()</span>
    
    <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">reset_default_graph</span><span class="p">()</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">/GPU:0</span><span class="sh">"</span><span class="p">):</span>
    

        <span class="c1">#init = tf.compat.v1.constant(sample_genotypes.T)
</span>        <span class="c1">#phi = tf.compat.v1.get_variable(name="phi", initializer = init, dtype = tf.float64)
</span>        
        <span class="n">phi</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">get_variable</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">phi</span><span class="sh">"</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">loci</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">initializers</span><span class="p">.</span><span class="nf">random_uniform</span><span class="p">(</span><span class="n">minval</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">maxval</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="n">input_data</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="sh">"</span><span class="s">float64</span><span class="sh">"</span><span class="p">,</span> <span class="p">(</span><span class="n">cells</span><span class="p">,</span> <span class="n">max_loci</span><span class="p">))</span> <span class="c1">#tf.constant("input",np.asmatrix(data))
</span>        <span class="n">input_loci</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="sh">"</span><span class="s">int32</span><span class="sh">"</span><span class="p">,</span> <span class="p">(</span><span class="n">cells</span><span class="p">,</span> <span class="n">max_loci</span><span class="p">))</span>
        <span class="n">loci_per_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="sh">"</span><span class="s">float64</span><span class="sh">"</span><span class="p">,</span> <span class="p">(</span><span class="n">cells</span><span class="p">))</span>
        <span class="n">trans</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
        <span class="n">broad_trans</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">broadcast_to</span><span class="p">(</span><span class="n">trans</span><span class="p">,[</span><span class="n">K</span><span class="p">,</span><span class="n">max_loci</span><span class="p">,</span><span class="n">cells</span><span class="p">])</span>
        <span class="n">untrans</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">broad_trans</span><span class="p">)</span>
        <span class="n">xtest</span> <span class="o">=</span> <span class="n">untrans</span><span class="o">-</span><span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span><span class="n">input_loci</span><span class="p">)</span>
        <span class="n">weight_data</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="sh">"</span><span class="s">float64</span><span class="sh">"</span><span class="p">,</span> <span class="p">(</span><span class="n">cells</span><span class="p">,</span><span class="n">max_loci</span><span class="p">,</span><span class="n">K</span><span class="p">))</span> <span class="c1">#tf.constant("weights",np.asmatrix(weights))
</span>    
        <span class="n">weighted</span> <span class="o">=</span> <span class="n">weight_data</span><span class="o">*</span><span class="n">xtest</span>
        <span class="n">powtest</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">pow</span><span class="p">(</span><span class="n">weighted</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">post</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">powtest</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">logsum</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">reduce_logsumexp</span><span class="p">(</span><span class="n">post</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">logsum</span><span class="p">)</span>
    
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="nc">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">).</span><span class="nf">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
            
        <span class="n">posteriors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">min_cost</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">weightsshape</span><span class="o">=</span><span class="p">[]</span>
        <span class="n">logsum_list</span><span class="o">=</span><span class="p">[]</span>
        <span class="n">cluster_list</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">repeat</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
        <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nf">global_variables_initializer</span><span class="p">()</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">repeat </span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">repeat</span><span class="p">))</span>
        <span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">1000</span>
        <span class="n">last_cost</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="nc">Session</span><span class="p">(</span><span class="n">config</span> <span class="o">=</span> <span class="n">session_conf</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">training_epochs</span><span class="p">):</span>
                <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">input_data</span><span class="p">:</span><span class="n">data</span><span class="p">,</span> <span class="n">weight_data</span><span class="p">:</span><span class="n">weightshape_np</span><span class="p">,</span> <span class="n">input_loci</span><span class="p">:</span><span class="n">data_loci</span><span class="p">})</span>
    
                <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">c</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">input_data</span><span class="p">:</span><span class="n">data</span><span class="p">,</span> <span class="n">weight_data</span><span class="p">:</span><span class="n">weightshape_np</span><span class="p">,</span> <span class="n">input_loci</span><span class="p">:</span><span class="n">data_loci</span><span class="p">})</span>
                    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">epoch </span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span><span class="o">+</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
                    <span class="c1">#if last_cost and ((last_cost-c)/c) &lt; 0.0001:
</span>                    <span class="k">if</span> <span class="n">min_cost</span> <span class="ow">and</span> <span class="n">last_cost</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">&gt;</span> <span class="n">min_cost</span> <span class="ow">and</span> <span class="p">(</span><span class="n">last_cost</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">c</span> <span class="o">-</span> <span class="n">min_cost</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.005</span><span class="p">:</span>
                        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">bailing out, too little progress toward minimum so far</span><span class="sh">"</span><span class="p">)</span>
                        <span class="k">break</span>
                    <span class="k">if</span> <span class="n">last_cost</span> <span class="ow">and</span> <span class="n">last_cost</span> <span class="o">-</span> <span class="n">c</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">last_cost</span> <span class="o">=</span> <span class="bp">None</span>
                        <span class="k">break</span>
                    <span class="n">last_cost</span> <span class="o">=</span> <span class="n">c</span>
            <span class="k">if</span> <span class="n">min_cost</span><span class="p">:</span>
                <span class="n">min_cost</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">min_cost</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">min_cost</span> <span class="o">=</span> <span class="n">c</span>
    
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">post</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">input_data</span><span class="p">:</span><span class="n">data</span><span class="p">,</span> <span class="n">weight_data</span><span class="p">:</span><span class="n">weightshape_np</span><span class="p">,</span> <span class="n">input_loci</span><span class="p">:</span><span class="n">data_loci</span><span class="p">})</span>
            <span class="n">posteriors</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">c</span><span class="p">,</span><span class="n">posterior</span><span class="p">))</span>
                
                
    
    <span class="n">sess</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
    
    <span class="n">posterior</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">posteriors</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>    
    <span class="n">clusters</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nf">return</span><span class="p">(</span><span class="n">clusters</span><span class="p">)</span>

</code></pre></div></div> <p>And then from your GPU-equipped computer, run the following:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">used_loci_indices</span><span class="p">,</span><span class="n">used_loci_set</span><span class="p">,</span><span class="n">used_loci</span><span class="p">,</span><span class="n">loci</span><span class="p">,</span><span class="n">loci_counts</span><span class="p">,</span><span class="n">cell_counts</span><span class="o">=</span><span class="nf">read_mtx</span><span class="p">(</span><span class="n">alt_matrix</span><span class="o">=</span><span class="sh">"</span><span class="s">alt.mtx</span><span class="sh">"</span><span class="p">,</span>
                                                                                <span class="n">ref_matrix</span><span class="o">=</span><span class="sh">"</span><span class="s">ref.mtx</span><span class="sh">"</span><span class="p">)</span>
<span class="n">clusters</span><span class="o">=</span><span class="nf">cluster_step</span><span class="p">(</span><span class="n">max_loci</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">K</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span><span class="n">training_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">repeats</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">cell_counts</span><span class="o">=</span><span class="n">cell_counts</span><span class="p">,</span>
                      <span class="n">loci_counts</span><span class="o">=</span><span class="n">loci_counts</span><span class="p">,</span><span class="n">used_loci_indices</span><span class="o">=</span><span class="n">used_loci_indices</span><span class="p">,</span>
                      <span class="n">cluster_tmp</span><span class="o">=</span><span class="sh">"</span><span class="s">cluster_simulated.tsv</span><span class="sh">"</span><span class="p">,</span><span class="n">known_cells</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">min_ref</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">min_alt</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="p">.</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <p>I randomly select 100 cells from each known cluster from an earlier experiment, and here is the performance in the case of imbalance-dataset:</p>]]></content><author><name></name></author><category term="Bioinformatics"/><category term="math"/><category term="genetic-demultiplexing"/><summary type="html"><![CDATA[speed up demultiplexing with GPU Tensorflow]]></summary></entry><entry><title type="html">‚öñÔ∏è How class imbalance might affect genetic demultiplexing of scRNA-seq data</title><link href="https://hoangmgh.github.io/blog/2023/benchmarking-souporcell/" rel="alternate" type="text/html" title="‚öñÔ∏è How class imbalance might affect genetic demultiplexing of scRNA-seq data"/><published>2023-10-31T21:01:00+00:00</published><updated>2023-10-31T21:01:00+00:00</updated><id>https://hoangmgh.github.io/blog/2023/benchmarking-souporcell</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2023/benchmarking-souporcell/"><![CDATA[<font size="5">1. Troubleshooting previous known problems </font> <p>From my experience with souporcell, I have seen that in some cases, one donor might be completely missing from the assignments. Instead of having 8 assigned donors, for example, you will have 7 donors with an equal number of cells, while one donor have around 20 cells - almost nothing. For example, here is one of our earlier experiment, where each cell has a hashtag identifying its origin (HTO), and we also used souporcell to assign a cell to a donor:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/soup_misassignment_example-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/soup_misassignment_example-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/soup_misassignment_example-1400.webp"/> <img src="/assets/img/soup_misassignment_example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Soup missasignment example" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.1: An example illustrating missing donors from souporcell experiments </div> <p>In two of our batches, we have 8 samples: the columns are the identities given by the hashtag, and the rows are the assignments from souporcell. As you can see, \(AO39PO\) and \(AO38PO\) are merged as \(Donor_2\), while \(Donor_7\) is trivial. The same phenomenon is also evident in the other Batch, DIA_3P_3C. What is similar in both cases is the low number of cells from the messed up Donors, i.e. 200-500 cells. By looking at the formula of the loss function and the fact that gaussian mixture might be very prone to class imbalance, I suspect that this is really the case.</p> <p><strong>2. Baseline scenario</strong></p> <p>And so, I attempted to simulate this situation by using our in-house data. From our Thyroid Autoimmune disease scRNA-seq dataset, I extracted the top 2000 cells from 7 Donors. All of these are CD45+ cells extracted from the Thyroid tissue. These cells are the one with the highest UMI and \(n_{genes}\) expressed, so at least we can be ascertain that coverage is not the problem. As a baseline, I run souporcell demultiplexing with 14,000 cells. In one run, here is the result that I have:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/14k_cells_soup-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/14k_cells_soup-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/14k_cells_soup-1400.webp"/> <img src="/assets/img/14k_cells_soup.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Soup missasignment example" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.2: An example showing the stochastic nature of the algorithm </div> <p>This is quite interesting! I expect that most of the cells will fall into its desired bin, i.e. the diagonal entries will consist each of approximately 2000 cells. Instead, what I see is the merging of 2 donors into one assignment, and the splitting of one authentic donor into two clusters! ‚ùó‚ùó<strong>This is very alarming!</strong> given that most people will take the souporcell result at face‚Äôs value. However, the truth is that you are seeing just 6 out of 7 donors.</p> <p>I then went on to repeat the same run again, but this time with a different parameter. Instead of using \(1024\) loci as the maximum number of features, I used \(200\) loci. Hopefully this can fix the issue! Indeed, we observe in the next run that most of the cells got accurately assigned:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/soup_good_example-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/soup_good_example-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/soup_good_example-1400.webp"/> <img src="/assets/img/soup_good_example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Soup missasignment example" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.3: A highly accurate result from one run with 14k cells, 2000 from each of 7 donors </div> <p>I think this is quite alarming, because most labs will likely run souporcell one time for one experiment and accept the result AS-IS. I also suspect that if you run this multiple times, perhaps you will arrive at a better solution than the one given in Fig.2. However, it might be true that one single run might give a suboptimal solution, local minima. When one tune the parameter drastically, the result changed, even though it might look like we have somewhat an equal number of cells.</p> <p><strong>Imbalance scenario 1:</strong></p> <p>Having finished this experiment, I went on to simulate an imbalance situation, where I subset 500 cells randomly from one donor, and keep 2000 cells from each of 7 donors. I then ran souporcell clustering procedure with the following parameters: \(n_{loci} = 200\), \(n_{loci} = 1024\), each with several repeats (\(n_{repeats} = 50\)):</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/soup_bad_example_12500-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/soup_bad_example_12500-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/soup_bad_example_12500-1400.webp"/> <img src="/assets/img/soup_bad_example_12500.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Soup missasignment example" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> An example of imbalance class in which 500 cells are from one Donor and 12000 from the remaining 6 donors. </div> <p>In another simulation of subsetting 500 cells from one donor, here is the result:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/soup_bad_example2_12500-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/soup_bad_example2_12500-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/soup_bad_example2_12500-1400.webp"/> <img src="/assets/img/soup_bad_example2_12500.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Soup missasignment example" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Another example of imbalance class in which 500 cells are from one Donor and 12000 from the remaining 6 donors. </div> <p>While we have 500 cells fall nicely into one category, they were merged with cells from another donor :(. <strong>Imbalance scenario 2:</strong></p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/soup_bad_example3_11500-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/soup_bad_example3_11500-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/soup_bad_example3_11500-1400.webp"/> <img src="/assets/img/soup_bad_example3_11500.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Soup missasignment example" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Another example of imbalance class in which 500 cells are from one Donor, 1000 from another and 10000 from the remaining 5 donors. </div> <p><strong>Using known genotypes to improve clustering</strong></p> <p>Given that this problem is an optimization problem, where we are trying to find the center of the clusters, which are essentially the genotypes of the donors, we can try to feed the known genotype data to the algorithm, if such an information is available. Souporcell implements this by using the known genotype as the initial value for the sparse-mixture gaussian model. This makes a lot of sense! Moreover, hypothetically speaking, this should also solve the imbalance class situation as a good initial value has been shown to eleviate this. A good initial value might help us get closer to the true \(\theta_i\).</p> <p>I attempted to create the genotype data for these 7 samples by using the paired-tissue data. While we can generate the genotype from the BAM files that we extract the cells from, this might cause some biases. With these genotypes information, here is the result in the 12500-cell class imbalance case:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/soup_good_example_genotype2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/soup_good_example_genotype2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/soup_good_example_genotype2-1400.webp"/> <img src="/assets/img/soup_good_example_genotype2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="A good example" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>What if some cells‚Äô identity are known ?</strong></p> <p>In our lab, we used to generate the corresponding hashtag data of the cells from GEX experiments. The hashtag are not quite reliable to infer the origin of the cells. Given this, I want to incorporate this information to help demultiplex the cells. Obviously, the hashtag identities can‚Äôt be used as ground-truth - it is in fact quite noisy, but it can get us closer to the ground truth. To simulate this scenario, I randomly select 100 cells from each sample, and assign a highest weight to its cluster of origin while 0 for the remaining clusters. Here is how souporcell‚Äôs code work. For each mixture centered at \(\theta_i\), its Tensorflow representation of the probability function is the following: \begin{equation} N(x=v_c | \theta_i) = e^{-\frac{\sqrt{(v_c-\theta_i)^TW(v_c-\theta_i)}}{2} } \end{equation}</p> <p>If an entry at loci \(j\) of \(v_c\) is not observed, then basically the \(j\) entry in the diagonal of \(W\) will be \(0\), so that unobserved loci will be ‚Äúmuted out‚Äù. If we consider cell \(v_c\) to be coming from the cluster with \(\theta_i\), then we want to set other \(N(x=v_c | \theta_j)=0\) where \(j \neq i\). We can do this by setting the diagonal of \(W\) to be all 1000 or some higher value. That way \(\sqrt{(v_c-\theta_i)^TW(v_c-\theta_i)}\) will be large enough.</p> <p>With this set-up, I tested the imbalance scenarior (500 x1 and 2000 x 6):</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/soup_good_example_genotype_100-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/soup_good_example_genotype_100-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/soup_good_example_genotype_100-1400.webp"/> <img src="/assets/img/soup_good_example_genotype_100.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Soup good assignment example" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.3: A highly accurate result from one run with 100 cells known from each cluster </div> <p>For future experiments, we might want to assign weights from ‚Äúhigh-quality‚Äù cells obtained from hashtag to assist demultiplexing.</p> <font size="5">2. Conclusion </font> <p>I think there are a few things I learned from these experiments with souporcell:</p> <ul> <li>the result given after a single run might be very inaccurate, and is driven by stochasticity. With that being said, rerunning an experiment with a different set of parameter might help</li> <li>If one can afford to genotype the samples, it is always better to include the known genotype as part of the run, instead of, for example, matching the found genotype taken from souporcell and match that with a known genotype later on</li> <li>I think we should also ask if imbalance class is a weakness of most unsupervised genetic demultiplexing tools out there. This is what I am trying to benchmark on.</li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="genetic-demultiplexing"/><category term="troubleshooting"/><summary type="html"><![CDATA[Benchmarking souporcell for scRNA-seq data in the case of class imbalance]]></summary></entry><entry><title type="html">üìè How do we measure correlation between matrices ?</title><link href="https://hoangmgh.github.io/blog/2023/RV2/" rel="alternate" type="text/html" title="üìè How do we measure correlation between matrices ?"/><published>2023-10-18T00:00:00+00:00</published><updated>2023-10-18T00:00:00+00:00</updated><id>https://hoangmgh.github.io/blog/2023/RV2</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2023/RV2/"><![CDATA[<p><strong>1.Matrices inner-product</strong></p> <p>One day I woke up and asked: What if we want to define a metric to calculate the correlation between two matrices. How would that be possible? I think this can be a bit confusing, because we might not understand what we mean by ‚Äúcorrelation‚Äù.</p> <p>To clarify this questions, I think it is good to go back to our definition. In fact, I think it might be a bit more useful to use the inner-product definition becauset it might be more intuitive and leave room for generalization. The inner-product helps us to relate the formality of ‚Äúlength‚Äù, ‚Äúdistance‚Äù, and ‚Äúangle‚Äù in a defined space.</p> <p>For correlation between two vectors in \(\mathbb{R^n}\), we want to</p> <p>\begin{equation} \rho (x,y)= \frac{\langle x-\mu_x , y-\mu_y \rangle}{|x-\mu_x||y-\mu_y|}=\cos \theta_{x,y} \end{equation} In the Euclidean space, you can replace the inner-product by the dot-product and you now have the Pearson correlation: \begin{equation} \rho (x,y) = \frac{(x-\mu_x) \cdot (y -\mu_y) } { |x-\mu_x| |y-\mu_y|} \end{equation} Technically speaking, the correlation between \(x\) and \(y\) can represent the cosine of the angle between two vectors. It is defined as the inner-product of centered vectors \(x\) and \(y\), weighted down by their length (hence the denominator).</p> <p>The inner product is a great concept to think about ‚Äúrelative‚Äù distance because it can be defined as a mapping such that \(\langle x,x \rangle = \|x\|\) So in the case that \(x\) and \(y\) are identical, the norminator reaches its maximum value, and the correlation is always at most 0.</p> <p>Now we can even generalize the inner-product to be defined for matrices, as long as your definition plays along with the formal definition of an ‚Äúinner-product‚Äù.In the case of matrices space, a well-known inner-product is the following. Given matrices \(A\) and \(B \in \mathbb{R^{f \times n}}\): \begin{equation} \langle A , B \rangle = tr(AB^T) <br/> \end{equation} This is saying that we calculate the dot products of vectors \(a_1 \cdot b_1\) , \(a_2 \cdot b_2\),‚Ä¶. and \(a_f \cdot b_f\). and summing them up, where \(a_i\) and \(b_i\) are the feature vectors of matrices \(A\) and \(B\) respectively. Thus the trace of \(AB^T\) gives us a ‚Äúsummary‚Äù value for how different two matrices are, by pairwise calculation of their feature vectors. A very important point I want to make is that dot product is a similarity measure, so the trace is summing up all the similarity.</p> <p>In the case that \(A=B\), we have \(\langle A ,B \rangle= tr(AA^T) = \|a_1\|+\|a_2\|+..+\|a_f\|\), which are the sum of the norms of feature columns in A. This is also similar to ‚Äúflattening‚Äù the matrix and treat it as the norm of the flattened vector. The trace inner-product is particularly useful, I believe, in the case that two matrices have the same size - same set of features, but different observations particularly.</p> <p><strong>2.RV coefficient</strong></p> <p>For two vectors \(A\) and \(B\) of different size, i.e. \(A \in \mathbb{R^{f \dots n_1}}\) and \(B \in \mathbb{R^{f \dots n_2}}\), there is no way that we can calculate \(\langle A B \rangle\). (Because these two don‚Äôt live on the same subspace). And so, we can ‚Äúdevise‚Äù a correlation between two matrices as: \begin{equation} \frac{\sum_{i=1}^f a_i b_i}{\sum_{i=1}^f |a_i|\sum_{i=1}^f |b_i|} \end{equation} In the case that \(A\) and \(B\) are of different size, but similiar set of features, we might want to calculate something like this:</p> <p>\begin{equation} \rho(A,B) = \frac{\langle AA^T, BB^T \rangle}{|AA^T||BB^T|} =\frac{tr(AA^TBB^T)}{|AA^T||BB^T|} \end{equation} Okay! So what this coefficient is measuring is basically the averaged similarity in the correlation pattern of the two matrices‚Äô feature sets. I then went on to try this measure on our genotype data.</p>]]></content><author><name></name></author><category term="Bioinformatics"/><category term="math"/><category term="bioinformatics"/><summary type="html"><![CDATA[Correlating matrices with RV coefficient and its application to correlating genotype arrays]]></summary></entry><entry><title type="html">Sparse-Mixture Gaussian clustering for genetic demultiplexing</title><link href="https://hoangmgh.github.io/blog/2023/math/" rel="alternate" type="text/html" title="Sparse-Mixture Gaussian clustering for genetic demultiplexing"/><published>2023-10-16T00:00:00+00:00</published><updated>2023-10-16T00:00:00+00:00</updated><id>https://hoangmgh.github.io/blog/2023/math</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2023/math/"><![CDATA[<p>I attempted to analyze the source code of <a href="https://github.com/wheaton5/souporcell">souporcell</a> and finally was able to understand its singlet identification step <a href="https://github.com/wheaton5/souporcell/blob/master/souporcell_pipeline.py">souporcell.py</a>. From my experience, the source code is much more straightforward to re-engineer than the mathematical formula given in the published paper, which might be a bit confusing.</p> <p>At the very core, souporcell attempts to model the genotype of each cell as a vector \(v_c\) of size \(1 \times l\), whose entry is calculated as \begin{equation} v_{cl} =\frac{r_{cl}}{a_{cl}+r_{cl}} <br/> \end{equation}</p> <p>That is, we represented a cell‚Äôs genotype by a vector, whose entries contains the fraction of reads that support the reference loci. If we have \(8\) reads mapped to a loci \(l\), where \(3\) reads show evidence for the reference genotype and \(5\) for the alternative, this value is \(3/8\), for example. The entries of this vector can take in the value of \(0\), \(0.5\), or \(1\), corresponding to the \(0/0\), \(0/1\) and \(1/1\) genotype. However, due to noise and coverage, the value can be skewed away.</p> <p><strong>1. Mixture Gaussian model</strong></p> <p>Assuming that each cell has its genotype data generated by vartrix, we can generate the vector for each cell by using the <strong>ref.mtx</strong> and the <strong>alt.mtx</strong> files given by souporcell. Now, the problem of assigning a cell an identity is equated to clustering the given cells into \(K\) group. Since single-cell data is too sparse, any methods that measure distance between cells might not be very effective. Moreover, we can think of the set of vectors \(v_c\) will cluster into \(K\) group, corresponding to \(K\) donors, and the center of these \(K\) groups will be the donor‚Äôs genotypes. We can use the Mixture-Gaussian method to solve this problem.</p> <p>Assuming that each cell (observation) is independently drawn from a mixture of \(K\) components, then the probability of seeing the vector \(v_c\) is:</p> <p>\begin{equation} P(v_c)= \sum_{i=1}^8 \pi_i N( \theta_i| K=i) = \sum_{i=1}^8 P(K=i) N(v=v_c |\theta_i , K=i) \end{equation}</p> <p>Here we can think of this as a two-fold process: for each component \(k\), we pick it with the probability \(P(K=i)\). Each component is ‚Äútagged‚Äù with a probability distribution. In our case, the distribution is Multivariate-Gaussian, so it is given by \(N(v=v_c ,\theta_i)\). A Multivariate-Gaussian take in two parameters: the center vector \(\theta_i\) and a covariance matrix \(\Sigma\). For simplicity, I think the author assume that most genes are pair-wise equivariant. The probability of ‚Äúpicking‚Äù the components must sum up to \(1\), and hence \(P(K=i)\) represents the weight of the component. Here, the author also assumes that the probability of drawing from each component is equal, so we can drop the terms \(P(K=i)\), and our probability \(P(v_c)\) can be thought of as an averaging of \(K\) probabilities.</p> <p>The formula for \(N(v=v_c \| \theta_i)\) is also well-defined:</p> <p>\begin{equation} N(v=v_c | \theta_i ,K=i) = e^{-\frac{1}{2}|v_c-\theta_i|_2 } \end{equation}</p> <p>The further your vector \(v_c\) from the centre \(\theta_i\), the smaller the \(l_2\) distance, and hence the bigger the probability.s When the distance is large enough, the exponent approach \(-\infty\), and hence the probability approaches \(e^{-\infty} \longrightarrow 0\)</p> <p><strong>2. Sparse implementation</strong></p> <p>Now, it is not very straightforward to calculate \(\|v_c-\theta_i\|\), given that not all loci of cell are observed. That is, most of entries of \(v_c\) wont have values, due to the fact that we don‚Äôt see any reads mapped to the loci (\(r_{cl}=a_{cl}=0\)) at loci \(l\). To deal with this situation, the author proposed the ‚Äúsparse‚Äù mixture implementation.</p> <p>Now, we can substitute the distance \(\|v_c-\theta_i\|\) with a version where only observed values contribute to the distance. To find the set of \(\theta_1\), \(\theta_2\),‚Ä¶\(\theta_K\), we use the Gradient-descent method to optimize our loss function.</p> <p>Note that the problem is now in fact an <strong>optimization</strong> problem, where a good set of parameters \(\theta_i\) is the one that maximize the probability of seeing the independent observations. Hence, we will be finding the centre vectors such that the following is maximized: \begin{equation} l(\theta_1,\theta_2,‚Ä¶,\theta_K)= \Pi_{i=1}^c P(v_i | \theta_1,\theta_2,..,\theta_K) \end{equation} which is also equivalent to maximizing the log (hence we call it the log-loss function) \begin{equation} log l(\theta)= log P(v_1 )+‚Ä¶+ log P(v_2) \end{equation}</p>]]></content><author><name></name></author><category term="Bioinformatics"/><category term="math"/><category term="genetic-demultiplexing"/><summary type="html"><![CDATA[An introduction to souporcell clustering with the mixture gaussian model]]></summary></entry><entry><title type="html">üõ†Ô∏è üì¢ Generate FASTQ files for new NovaseqX sequencing data</title><link href="https://hoangmgh.github.io/blog/2023/NovaseqX/" rel="alternate" type="text/html" title="üõ†Ô∏è üì¢ Generate FASTQ files for new NovaseqX sequencing data"/><published>2023-06-28T00:00:00+00:00</published><updated>2023-06-28T00:00:00+00:00</updated><id>https://hoangmgh.github.io/blog/2023/NovaseqX</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2023/NovaseqX/"><![CDATA[<p>If you happen to align the most recent Novaseq runs with the new technology, chances are that you will receive an error somewhere in cellranger-mkfastq</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Log message:
Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
File <span class="s2">"/software/cellranger-6.0.1/external/martian/adapters/python/martian_shell.py"</span>, line 659, <span class="k">in </span>_main
stage.main<span class="o">()</span>
File <span class="s2">"/software/cellranger-6.0.1/external/martian/adapters/python/martian_shell.py"</span>, line 618, <span class="k">in </span>main
self._run<span class="o">(</span>lambda: self._module.main<span class="o">(</span>args, outs<span class="o">))</span>
File <span class="s2">"/software/cellranger-6.0.1/external/martian/adapters/python/martian_shell.py"</span>, line 589, <span class="k">in </span>_run
cmd<span class="o">()</span>
File <span class="s2">"/software/cellranger-6.0.1/external/martian/adapters/python/martian_shell.py"</span>, line 618, <span class="k">in</span> &lt;lambda&gt;
self._run<span class="o">(</span>lambda: self._module.main<span class="o">(</span>args, outs<span class="o">))</span>
File <span class="s2">"/software/cellranger-6.0.1/mro/tenkit/stages/make_fastqs/make_fastqs_preflight/__init__.py"</span>, line 53, <span class="k">in </span>main
<span class="o">(</span>rta_version, _, bcl_params<span class="o">)</span> <span class="o">=</span> tk_bcl.get_rta_version<span class="o">(</span>args.run_path<span class="o">)</span>
File <span class="s2">"/software/cellranger-6.0.1/lib/python/tenkit/bcl.py"</span>, line 144, <span class="k">in </span>get_rta_version
application_version <span class="o">=</span> tree.getroot<span class="o">()</span>.find<span class="o">(</span><span class="s2">"ApplicationVersion"</span><span class="o">)</span>.text
AttributeError: <span class="s1">'NoneType'</span> object has no attribute <span class="s1">'text'</span>
</code></pre></div></div> <p>It seems that in the sequencing folder of this run doesnt have some attribute required by cellranger. However, cellranger is just a wrapper of bcl2fastq, and we won‚Äôt need the attribute ‚Äòtext‚Äô to fix it anyway. So the solution, as suggested by the 10x website, is to manually generate the fastq from BCL files. I would copied the files to bcb-data and run bcl2fastq. The tricky part is that cellranger-mkfastq would do it dirty work to translate its samplesheet to bcl2fastq‚Äôs samplesheet (these two samplesheets are different and you can‚Äôt feed cellranger-mkfastq samplesheet to bcl2fastq).</p> <p>Here are two ways that you can generate the samplesheet for bcl2fastq:</p> <ol> <li>Use an existing flowcell with the same chemistry and configuration (dual-index or single-index) as the one you obtained from Novaseq, and run cellranger on that flowcell. So for example, go to a directory that you want, and run:</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cellranger mkfastq  <span class="se">\</span>
<span class="nt">-R</span> /existing-flowcell-dir/230421_NB551582_0149_AHF3C2BGXT 
<span class="nt">--sample-sheet</span> /some-dir/samplesheet_for_new_run.csv <span class="nt">--barcode-mismatches</span><span class="o">=</span>0
</code></pre></div></div> <p>samplesheet here would be your samplesheet for this NovaseqX run. You don‚Äôt have to wait for this to run, just cancel it once bcl2fastq task is done. Inside your directory, you will have a folder of your flowcell, something like HF3C2BGXT. You can do</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> find <span class="nb">.</span> |grep csv
</code></pre></div></div> <p>to find the bcl2fastq samplesheet:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./MAKE_FASTQS_CS/MAKE_FASTQS/PREPARE_SAMPLESHEET/fork0/chnk0-u2a1f9c52b1/files/samplesheet.csv
./MAKE_FASTQS_CS/MAKE_FASTQS/PREPARE_SAMPLESHEET/fork0/chnk0-u2a1f9c52b1/files/input_samplesheet.csv
</code></pre></div></div> <p>There are two files here, just use the one called samplesheet.csv and feed that into bcl2fastq:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bcl2fastq <span class="nt">-i</span> /projects/Hoang/230614_SL-EXC_0018_B223YNKLT3/Data/Intensities/BaseCalls/ <span class="nt">-o</span> /projects/Hoang/230614_SL-EXC_0018_B223YNKLT3/out/ 
<span class="nt">--sample-sheet</span> ./MAKE_FASTQS_CS/MAKE_FASTQS/PREPARE_SAMPLESHEET/fork0/chnk0-u2a1f9c52b1/files/samplesheet.csv 
</code></pre></div></div> <p>You can do this, or you can manually create the bcl2fastq samplesheet by search up 10x barcode files. This is tedious though‚Ä¶ You have to search each index to get the write oligo barcodes.</p>]]></content><author><name></name></author><category term="bioinformatics"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[learn to trick your software with this tip]]></summary></entry><entry><title type="html">üìà Some visualization tips for scRNA-seq data</title><link href="https://hoangmgh.github.io/blog/2023/sc-vis/" rel="alternate" type="text/html" title="üìà Some visualization tips for scRNA-seq data"/><published>2023-02-25T21:01:00+00:00</published><updated>2023-02-25T21:01:00+00:00</updated><id>https://hoangmgh.github.io/blog/2023/sc-vis</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2023/sc-vis/"><![CDATA[<p>While working on the Thyroid Autoimmune Disease project, I took the chance to rewrite existing visualization tools so that we can personalize them. For example, we can add components that are useful for communicative purposes.</p> <p>While looking at the source code of <a href="https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_dotplot.py#L792-L987">scanpy‚Äôs dotplot</a>, I realize that there are two very important parameters that tend to be glossed over: <strong>mean_only_expressed</strong> and <strong>DEFAULT_SIZE_EXPONENT</strong>. To make the difference between the dots bigger, scanpy raise the size of the dots to an exponent, default at \(1.5\). This makes dots bigger than it is expected in a linear scale. The <strong>mean_only_expressed</strong> is adjustable, and this controls whether one wants to average over the non-zero value of a given gene.</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dotplot_thyroid_example-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dotplot_thyroid_example-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dotplot_thyroid_example-1400.webp"/> <img src="/assets/img/dotplot_thyroid_example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lineage dotplot" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A dotplot showing the defining markers of main cell types in Thyroid tissue </div> <p>One feature I really like is the horizontal strips for each cell. This is particularly useful for readers who want to navigate a specific gene in the middle of the dotplot. The other feature that might be useful is a colorbars for the cell populations - these should also match the color of the UMAP, as well. I personally prefer to set the color for the doublets as gray, because it is biologically interesting and we want readers to gloss over this population. For example, this dotplot can go really well with the UMAP:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/umap_thyroid_example-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/umap_thyroid_example-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/umap_thyroid_example-1400.webp"/> <img src="/assets/img/umap_thyroid_example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lineage dotplot" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> An UMAP showing main cell types in Thyroid tissue </div> <p>Another modification we can make to the scanpy dotplot is plotting protein and RNA at the same time, side-by-side, using a different cmap, e.g. Reds for RNA and Blues for Protein. I find this quite satisfying visually:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dotplot_thyroid_example2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dotplot_thyroid_example2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dotplot_thyroid_example2-1400.webp"/> <img src="/assets/img/dotplot_thyroid_example2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lineage dotplot" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A dotplot showing the defining markers of main B-cell subtypes in the Thyroid dataset </div> <font size="5"> 2. Boxplot for cell population's frequency </font> <p>We can also use the same dark grey and white strips to aid the reading in boxplot as well:</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/boxplot_thyroid-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/boxplot_thyroid-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/boxplot_thyroid-1400.webp"/> <img src="/assets/img/boxplot_thyroid.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lineage boxplot" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A boxplot showing the frequency of different cell types in the Thyroid tissue </div> <p>I also mix boxplot with stripplot in seaborn, which wiggle dots vertically or horizontally so that they don‚Äôt overlay each other. This can be particularly useful if we have densely packed dots. Moreover, we can also set the color of the dots and the boxplots to be the same. We also decided to, for example, set the color of the immune cells to the red-brown shades, while the non-lymphocytes the green-blue shades.</p> <p>Simultaneously, it can be useful to break down your boxplot into multiple subplots. In our example, the Epithelial has a very frequency compared to other cell types, so it might be helpful to put them as a seperate subplot. Otherwise, the epithelial might dominate the frequency of other cell types.</p> <font size="5"> 3. Source code </font> <p>If you are interested in using my codes, feel free to download the source code below and re-appropriate them to your liking:</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="visualization"/><category term="single-cell"/><summary type="html"><![CDATA[make informative heatmap, boxplot, dotplot, etc for your single-cell paper]]></summary></entry><entry><title type="html">üì¢üìè Implementing weighted PCA in python</title><link href="https://hoangmgh.github.io/blog/2023/wPCA/" rel="alternate" type="text/html" title="üì¢üìè Implementing weighted PCA in python"/><published>2023-02-01T00:00:00+00:00</published><updated>2023-02-01T00:00:00+00:00</updated><id>https://hoangmgh.github.io/blog/2023/wPCA</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2023/wPCA/"><![CDATA[<p>In <a href="https://doi.org/10.1016/j.medj.2022.05.002">Cross-tissue, single-cell stromal atlas identifies shared pathological fibroblast phenotypes in four chronic inflammatory diseases</a>, the authors use a technique called ‚Äúweighted PCA‚Äù, together with harmony, to remove batch effect across a wide variety of diseases. The most important observation they made is the stark difference between the number of cells between tissues. To dive into this, I would like to explain the concept of weighted PCA, first by formalizing the idea of weighted expectation, weighted variance, and eventually weighted covariance matrix. While there are various implementation of weighted PCA out there, this is perhaps the easiest implementation, most intuitive, and also well generalized from the original definition of PCA. First, we can define a weighted inner-product in the Euclidean space:</p> <p>\begin{equation} \langle x,y \rangle_W = x^T W y<br/> \end{equation}</p> <p>where the diagonal entries of \(W\) stores the weights (\(diag(W)=\vec{w}\)) and their entries must sum to \(1\). You can check that this is indeed an inner product by checking its properties. As a result, the weighted norm simply follows:</p> <p>\begin{align} |x|_W = \langle x,x \rangle_W = (x^T W x)^{1/2} \end{align}</p> <p>Then, we can define a weighted mean of a vector \(\vec{x} \in \mathbb{R^n}\). You can think of a mean as a dot-product as well!</p> <p>\begin{equation} \mu_x^W = \vec{x}^T \cdot \vec{w} = \vec{x}^T \cdot W \cdot \vec{1} = \langle x, \vec{1} \rangle_W \end{equation}</p> <p>and \(diag(W)=w\). You can always replace the weight vector with the diagonal matrix \(W\) of the same size! In the unweighted case, we simply have all entries of \(w\) to be \(\frac{1}{n}\). Now, we can define weighted covariance of \(x\) and \(y\) as:</p> <p>\begin{align} Cov(x,y)_W = \langle x-\mu_x^W ,y-\mu_y^W \rangle_W = (x-\mu_x^W)^T W (y-\mu_y^W) \end{align} In short, most of our measures, i.e. correlation, covariance, mean, variance, are replaced with the weighted version. I think it makes sense that this has to be built from the ground up using a different version of the dot-product. The weights for each observation can also be interpreted as corresponding to the frequency of each observation. In an imbalance situation, it is favorable to incorporate this weight to reflect the frequency of different classes of observation.</p> <p>Now, for a large matrix \(A\) of form \(\mathbb{R^{g \times c }}\), we can ‚Äúbulk‚Äù compute the sample covariance matrix the following way. First, center each gene at the weighted mean and inversely scale them by the weighted standard deviation. From there, we can scale the matrix observation-wise (so that later on \(AA^T\) actually sample correlation matrix):</p> <p>The covariance matrix is, in fact, no longer \(AA^T\) but \(AWA^T\), due to our definition of the covariance above. The weighted PCA from here can be rewritten as diagonalizing (eigendecomposition): \begin{equation} AWA^T = AW^{1/2} W^{1/2}A^T = AW^{1/2} (AW^{1/2})^T \end{equation} Here \(W\) is diagonal so \(W^{1/2}\) is the same as its transpose. Therefore, diagonalizing \(AWA^T\) is equivalent to running SVD for \(AW^{1/2}\). We can then write \(AW^{1/2}\) as \begin{equation} AW^{1/2}=USV \end{equation} and hence \begin{equation} A = USVW^{1/2} \end{equation} Under the new orthogonal basis spanned by \(U\), the coordinates are now given by \(SVW^{1/2}\)</p> <p>Here is the python code to run weighted PCA on your single-cell anndata.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">weighted_pca</span><span class="p">(</span><span class="n">anndata</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">n_comps</span><span class="p">,</span><span class="n">zero_center</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">svd_solver</span><span class="o">=</span><span class="sh">"</span><span class="s">arpack</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">return_info</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">use_highly_variable</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">corr</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="o">=</span><span class="sh">"</span><span class="s">float32</span><span class="sh">"</span><span class="p">,</span><span class="n">chunked</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">chunk_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">max_value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">copy</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="c1">####first is to create a new anndata and a diagonal matrix:
</span>    <span class="c1">####The input to this should be a 
</span>    <span class="kn">from</span> <span class="n">scipy.sparse.linalg</span> <span class="kn">import</span> <span class="n">svds</span>
    <span class="kn">from</span> <span class="n">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
    <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
    <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

    <span class="k">def</span> <span class="nf">vars</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> Variance of sparse matrix a
        var = mean(a**2) - mean(a)**2
        </span><span class="sh">"""</span>
        <span class="n">a_squared</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
        <span class="n">a_squared</span><span class="p">.</span><span class="n">data</span> <span class="o">**=</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">a_squared</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">stds</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> Standard deviation of sparse matrix a
        std = sqrt(var(a))
        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">vars</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span>

    <span class="n">wanndataX</span><span class="o">=</span><span class="n">anndata</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>

    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_row_scale</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">mu</span><span class="o">=</span><span class="n">wanndataX</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">sig</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="nf">stds</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)).</span><span class="n">T</span><span class="p">)</span>
    <span class="c1">##### We want to scale the old data (not the new data using mean and std of the new data):
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">shifting by weighted mean:</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">wanndataX</span><span class="o">=</span><span class="n">scipy</span><span class="p">.</span><span class="n">sparse</span><span class="p">.</span><span class="nf">csr_matrix</span><span class="p">(</span><span class="n">anndata</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">row scaling with weighted standard deviation</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_column_scale</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>

    <span class="k">del</span> <span class="n">mu</span><span class="p">,</span><span class="n">sig</span>
    <span class="k">if</span> <span class="n">corr</span><span class="o">=</span><span class="bp">True</span><span class="p">:</span>
        <span class="c1">#####And then run scaling on this matrix one more time observation-wise:
</span>        <span class="n">mu</span><span class="o">=</span><span class="n">wanndataX</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">mu</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">sig</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="nf">stds</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">sig</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">wanndataX</span><span class="o">=</span><span class="n">scipy</span><span class="p">.</span><span class="n">sparse</span><span class="p">.</span><span class="nf">csr_matrix</span><span class="p">(</span><span class="n">wanndataX</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s"> scaling with weighted standard deviation</span><span class="sh">"</span><span class="p">)</span>

        <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_row_scale</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
    <span class="c1">##### and then multiply this column sqrt of weights:
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">adding weights:</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_row_scale</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
    <span class="k">del</span> <span class="n">mu</span><span class="p">,</span><span class="n">sig</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">running SVDs:</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nf">svds</span><span class="p">(</span> <span class="n">wanndataX</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">n_comps</span><span class="p">)</span>
    <span class="n">v</span><span class="o">=</span><span class="n">scipy</span><span class="p">.</span><span class="n">sparse</span><span class="p">.</span><span class="nf">csr_matrix</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    


    <span class="c1">############ 
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">outputing anndata:</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">wanndata</span><span class="o">=</span><span class="n">anndata</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
    <span class="n">wanndata</span><span class="p">.</span><span class="n">varm</span><span class="p">[</span><span class="sh">"</span><span class="s">PCs</span><span class="sh">"</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">w</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">weights</span><span class="p">)).</span><span class="n">T</span><span class="p">)</span>
    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_column_scale</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_row_scale</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

    
    <span class="n">wanndata</span><span class="p">.</span><span class="n">obsm</span><span class="p">[</span><span class="sh">"</span><span class="s">X_wpca</span><span class="sh">"</span><span class="p">]</span><span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">v</span><span class="p">.</span><span class="nf">todense</span><span class="p">().</span><span class="n">T</span><span class="p">)</span>
    <span class="n">gc</span><span class="p">.</span><span class="nf">collect</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">copy</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">wanndata</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="Bioinformatics"/><category term="math"/><category term="genetic-demultiplexing"/><summary type="html"><![CDATA[Learning low-rank approximation with different methods]]></summary></entry><entry><title type="html">üì¢ Principle Component Analysis (PCA) - intuition</title><link href="https://hoangmgh.github.io/blog/2022/PCA/" rel="alternate" type="text/html" title="üì¢ Principle Component Analysis (PCA) - intuition"/><published>2022-10-04T00:00:00+00:00</published><updated>2022-10-04T00:00:00+00:00</updated><id>https://hoangmgh.github.io/blog/2022/PCA</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2022/PCA/"><![CDATA[<p>I think most scientists who have the privilege to work with single-cell RNA-seq data tend to overlook the concept of PCA. However, PCA is an essential step in of our single-cell dimension reduction and clustering pipeline. When I first learn about the Principle Component Analysis, I was taught from the perspective of a linear ‚Äútransformation‚Äù of the original data, e.g. scaling and rotation, in such a way that the resulting matrix have <strong>maximized variance</strong>. This was also taught using data with only 3 features and k=2 components - obviously because it is easy to visualize in 2D space. While this definition is useful and easy to compute for new-comers, honestly , I think it is not intuitive enough and doesn‚Äôt do justice to the whole purpose of PCA. In reality, for very high dimensional data, the 2D intuition won‚Äôt help us generalize to n-dimensions.</p> <p>I would like to explain this concept formally in the perspective of a low-rank approximation problem. PCA can be characterized as finding a low-dimensional ‚Äúbox‚Äù that can ‚Äúfit‚Äù our matrix, which currently live in a high dimension, e.g. 30,000 features. This is only plausible as we assume there is some <strong>inherent structure</strong> in our data that is low dimensional. Specifically, what is ‚Äúlow‚Äù here is the <strong>rank</strong> of the data.</p> <p><strong>1. Rank of a matrix</strong></p> <p>A linear combination of vectors \(v_1\), \(v_2\),‚Ä¶ \(v_k\) is simply defined as a weighted sum of the form \begin{align} a_1 v_1 + a_2 v_2 + ‚Ä¶ + a_k v_k = [\vec{v_1} \ \vec{v_2} \ ‚Ä¶ \ \vec{v_n}] \end{align}</p> <p>A collection of vectors \(v_1\), \(v_2\),‚Ä¶. \(v_k\) is linearly independent if there is no linear combination of them that produce the zero vector, except for the trivial 0-weighted linear combination.</p> <p>The rank of a matrix \(A\) is the size of the largest subset of \(A\)‚Äôs columns which are linearly independent. If \(rank(A)=r\), then if one picks \(r+1\) random columns, they are guaranteed to be <strong>linearly dependent</strong>. There is also another way to define the rank. We define the column space of a matrix as the set of all possible linear combination of its columns. A basis for the column space is a linear independent collection of elements of the column space of the largest possible size. Given this, every element of the column space can be represented as a linear combination of the elements in a basis. If we define the basis to be a matrix \(B\), then we can write \(A\) as: \begin{equation} A = BC = [\vec{b_1} \ \vec{b_2} \ ‚Ä¶ \ \vec{b_r}] \end{equation} where \(a_i\) are of size \(\mathbb{R^{r}}\).</p> <p><strong>2. Low-Rank Approximation</strong></p> <p>In real-world, the data are not always low-rank, but <strong>approximately</strong> low rank. This means we can find a substituting matrix \(\overline{A}\) of low rank so that \begin{equation} E = A - \overline{A} \end{equation} is small by some sense. What does this mean? and how should we find an obscured \(\overline{A}\) ? In simple terms, we can think of projecting \(A\) onto a subspace \(S\) of rank \(k\). To be more precise, we are looking for a subspace S spanned by the basis \(V=(w_1 w_2 ... w_k)\) such that \(\overline{A} = proj_S (A) \in span(V)\) As always, we can define this projection in terms of a projection matrix \(V\): \begin{equation} \overline{A} = VV^T (A) = [VV^Ta_1 VV^Ta_2‚Ä¶.VV^Ta_n] \end{equation} what we are doing here is in fact projecting each column vector of \(A\), i.e. \(a_i\), onto the subspace spanned by \(V\). To minimize the distance between $A$ and its projection is very similar to jointly minimimze the distance between each column and their projection. Specifically, we are trying to minimize with the euclidean distance the following: \(f(A) = \sum_{i=1}^k \|VV^T a_i - a_i\|\)</p> <p>If we implement singular-value decomposion on \(A\) and obtain \(A=U\sum V^T\), then a well-known result from Ekart-Young-Mirsky theorem is that \(U_l\) is among a bunch of \(W\)s that can minimize \(f(A)\), where we define \(U_l\) to be the first \(l\) columns of \(U\) obtained from the SVD of \(A\). Moreover, we also know that vector \(V\) is consisted of the eigenvectors of \(AA^T\): \begin{equation} AA^T = V\sum{ }^2V^T \end{equation}</p> <p>In summary, we know that principle components of a given matrix is the <strong>orthogonal projection</strong> of the input data into a subspace spanned by the first \(l\) columns of the singular matrix $S$.</p> <div class="row" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/pca_thumb-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/pca_thumb-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/pca_thumb-1400.webp"/> <img src="/assets/img/pca_thumb.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lineage dotplot" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> An example of projecting 2D data onto a subspace spanned by 1D vector </div>]]></content><author><name></name></author><category term="Bioinformatics"/><category term="math"/><category term="single-cell"/><summary type="html"><![CDATA[Learning PCA from the perspective of a low-rank approximation]]></summary></entry><entry><title type="html">üìè Projection in linear subspace</title><link href="https://hoangmgh.github.io/blog/2022/projection/" rel="alternate" type="text/html" title="üìè Projection in linear subspace"/><published>2022-10-04T00:00:00+00:00</published><updated>2022-10-04T00:00:00+00:00</updated><id>https://hoangmgh.github.io/blog/2022/projection</id><content type="html" xml:base="https://hoangmgh.github.io/blog/2022/projection/"><![CDATA[<p>Often times, we want to find an orthogonal projection of a vector onto a subspace. Instead of writing this in matrix multiplication, here is what I like to write, using abstract algebra terms such as inner-product. The inner-product is a great tool to abstractly think about concepts such as angle and distance.</p> <p>First, a subspace S of \(rank(S)=k\) can be defined solely based on a chosen set of orthogonal basis \(V=(\vec{w_1},\vec{w_2},...\vec{w_k})\).</p> <p>The projection of an arbitrary vector \(x\) onto \(S\) is defined as a vector in \(S\) that is the closest to \(x\), and it can be written as</p> <p>\begin{equation} proj_S(x)= proj_{w_1} (x) + proj_{w_2} (x) + ‚Ä¶ + proj_{w_k} = \sum_{i=1}^k \alpha_i w_i (x) \end{equation}</p> <p>Indeed, the projection must be within the span of \(V\), and \(\alpha_i w_i = proj_{w_1} (x)\). Similarly, we write</p> <p>\begin{equation} proj_S(x) = \sum_{i=1}^k \frac{\langle x,v_i \rangle}{|v_i|} v_i = \sum_{i=1}^k \langle x,v_i \rangle v_i \end{equation} since our basis is chosen to be orthonormal, i.e \(\| v_i \| =1\) for all \(i=1,2...k\). Now, there are different kind of inner-product. In the euclidean space, we are ‚Äúendowed‚Äù with the dot-product inner-product, and so \begin{equation} proj_S(x) = \sum_{i=1}^k x v_i^T v_i = VV^T x<br/> \end{equation} where we define \(V\) as \begin{bmatrix} V=[w_1 \ w_2 \ ‚Ä¶ \ w_n] \end{bmatrix}</p> <p>This will be quite useful for more advanced concepts such as SVD (PCA).</p>]]></content><author><name></name></author><category term="Bioinformatics"/><category term="math"/><category term="notes"/><summary type="html"><![CDATA[Abstract algebra - projection in terms of inner-products]]></summary></entry></feed>