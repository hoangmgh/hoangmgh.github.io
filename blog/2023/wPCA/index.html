<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>üì¢üìè Implementing weighted PCA in python | Hoang (Anh) Tran</title> <meta name="author" content="Hoang (Anh) Tran"> <meta name="description" content="Learning low-rank approximation with different methods"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hoangmgh.github.io/blog/2023/wPCA/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <script async src="https://www.googletagmanager.com/gtag/js?id={{%20site.google_analytics%20}}"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1W7V2Y0MXW");</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Hoang¬†</span>(Anh)¬†Tran</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Bioinformatics<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Arts</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">üì¢üìè Implementing weighted PCA in python</h1> <p class="post-meta">February 1, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> ¬† ¬∑ ¬† <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> math</a> ¬† <a href="/blog/tag/genetic-demultiplexing"> <i class="fa-solid fa-hashtag fa-sm"></i> genetic-demultiplexing</a> ¬† ¬† ¬∑ ¬† <a href="/blog/category/bioinformatics"> <i class="fa-solid fa-tag fa-sm"></i> Bioinformatics</a> ¬† </p> </header> <article class="post-content"> <div id="markdown-content"> <p>In <a href="https://doi.org/10.1016/j.medj.2022.05.002" rel="external nofollow noopener" target="_blank">Cross-tissue, single-cell stromal atlas identifies shared pathological fibroblast phenotypes in four chronic inflammatory diseases</a>, the authors use a technique called ‚Äúweighted PCA‚Äù, together with harmony, to remove batch effect across a wide variety of diseases. The most important observation they made is the stark difference between the number of cells between tissues. To dive into this, I would like to explain the concept of weighted PCA, first by formalizing the idea of weighted expectation, weighted variance, and eventually weighted covariance matrix. While there are various implementation of weighted PCA out there, this is perhaps the easiest implementation, most intuitive, and also well generalized from the original definition of PCA. First, we can define a weighted inner-product in the Euclidean space:</p> <p>\begin{equation} \langle x,y \rangle_W = x^T W y<br> \end{equation}</p> <p>where the diagonal entries of \(W\) stores the weights (\(diag(W)=\vec{w}\)) and their entries must sum to \(1\). You can check that this is indeed an inner product by checking its properties. As a result, the weighted norm simply follows:</p> <p>\begin{align} |x|_W = \langle x,x \rangle_W = (x^T W x)^{1/2} \end{align}</p> <p>Then, we can define a weighted mean of a vector \(\vec{x} \in \mathbb{R^n}\). You can think of a mean as a dot-product as well!</p> <p>\begin{equation} \mu_x^W = \vec{x}^T \cdot \vec{w} = \vec{x}^T \cdot W \cdot \vec{1} = \langle x, \vec{1} \rangle_W \end{equation}</p> <p>and \(diag(W)=w\). You can always replace the weight vector with the diagonal matrix \(W\) of the same size! In the unweighted case, we simply have all entries of \(w\) to be \(\frac{1}{n}\). Now, we can define weighted covariance of \(x\) and \(y\) as:</p> <p>\begin{align} Cov(x,y)_W = \langle x-\mu_x^W ,y-\mu_y^W \rangle_W = (x-\mu_x^W)^T W (y-\mu_y^W) \end{align} In short, most of our measures, i.e. correlation, covariance, mean, variance, are replaced with the weighted version. I think it makes sense that this has to be built from the ground up using a different version of the dot-product. The weights for each observation can also be interpreted as corresponding to the frequency of each observation. In an imbalance situation, it is favorable to incorporate this weight to reflect the frequency of different classes of observation.</p> <p>Now, for a large matrix \(A\) of form \(\mathbb{R^{g \times c }}\), we can ‚Äúbulk‚Äù compute the sample covariance matrix the following way. First, center each gene at the weighted mean and inversely scale them by the weighted standard deviation. From there, we can scale the matrix observation-wise (so that later on \(AA^T\) actually sample correlation matrix):</p> <p>The covariance matrix is, in fact, no longer \(AA^T\) but \(AWA^T\), due to our definition of the covariance above. The weighted PCA from here can be rewritten as diagonalizing (eigendecomposition): \begin{equation} AWA^T = AW^{1/2} W^{1/2}A^T = AW^{1/2} (AW^{1/2})^T \end{equation} Here \(W\) is diagonal so \(W^{1/2}\) is the same as its transpose. Therefore, diagonalizing \(AWA^T\) is equivalent to running SVD for \(AW^{1/2}\). We can then write \(AW^{1/2}\) as \begin{equation} AW^{1/2}=USV \end{equation} and hence \begin{equation} A = USVW^{1/2} \end{equation} Under the new orthogonal basis spanned by \(U\), the coordinates are now given by \(SVW^{1/2}\)</p> <p>Here is the python code to run weighted PCA on your single-cell anndata.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">weighted_pca</span><span class="p">(</span><span class="n">anndata</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">n_comps</span><span class="p">,</span> <span class="n">corr</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                 <span class="n">max_value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">copy</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
   <span class="sh">'''</span><span class="s">
        This function calculate a weighted version of PCA as suggested in https://doi.org/10.1016/j.medj.2022.05.002
        by Korsunsky et al
        input:
                anndata: a log10CPM normalized count matrix. This should not be scaled in any ways
                n_comps: number of components for wPCA

    </span><span class="sh">'''</span>
    <span class="kn">from</span> <span class="n">scipy.sparse.linalg</span> <span class="kn">import</span> <span class="n">svds</span>
    <span class="kn">from</span> <span class="n">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
    <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
    <span class="k">assert</span> <span class="n">anndata</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">max_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">max_value</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">def</span> <span class="nf">vars</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> Variance of sparse matrix a
        var = mean(a**2) - mean(a)**2
        </span><span class="sh">"""</span>
        <span class="n">a_squared</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
        <span class="n">a_squared</span><span class="p">.</span><span class="n">data</span> <span class="o">**=</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">a_squared</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">stds</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> Standard deviation of sparse matrix a
        std = sqrt(var(a))
        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">vars</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span>

    <span class="n">wanndataX</span><span class="o">=</span><span class="n">anndata</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>

    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_row_scale</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">mu</span><span class="o">=</span><span class="n">wanndataX</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">sig</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="nf">stds</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)).</span><span class="n">T</span><span class="p">)</span>
    <span class="c1">##### We want to scale the old data (not the new data using mean and std of the new data):
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">shifting by weighted mean:</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">wanndataX</span><span class="o">=</span><span class="n">scipy</span><span class="p">.</span><span class="n">sparse</span><span class="p">.</span><span class="nf">csr_matrix</span><span class="p">(</span><span class="n">anndata</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">row scaling with weighted standard deviation</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_column_scale</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>

    <span class="k">del</span> <span class="n">mu</span><span class="p">,</span><span class="n">sig</span>
    <span class="k">if</span> <span class="n">corr</span><span class="o">=</span><span class="bp">True</span><span class="p">:</span>
        <span class="c1">#####And then run scaling on this matrix one more time observation-wise:
</span>        <span class="n">mu</span><span class="o">=</span><span class="n">wanndataX</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">mu</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">sig</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="nf">stds</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">sig</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">wanndataX</span><span class="o">=</span><span class="n">scipy</span><span class="p">.</span><span class="n">sparse</span><span class="p">.</span><span class="nf">csr_matrix</span><span class="p">(</span><span class="n">wanndataX</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s"> scaling with weighted standard deviation</span><span class="sh">"</span><span class="p">)</span>

        <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_row_scale</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">wanndataX</span><span class="p">[</span><span class="n">wanndataX</span><span class="o">&gt;=</span><span class="n">max_value</span><span class="p">]</span><span class="o">=</span><span class="n">max_value</span>
            <span class="n">wanndataX</span><span class="p">[</span><span class="n">wanndataX</span><span class="o">&lt;=-</span><span class="mi">1</span><span class="o">*</span><span class="n">max_value</span><span class="p">]</span><span class="o">=-</span><span class="mi">1</span><span class="o">*</span><span class="n">max_value</span>

    <span class="c1">##### and then multiply this column sqrt of weights:
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">adding weights:</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_row_scale</span><span class="p">(</span><span class="n">wanndataX</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
    <span class="k">del</span> <span class="n">mu</span><span class="p">,</span><span class="n">sig</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">running SVDs:</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nf">svds</span><span class="p">(</span> <span class="n">wanndataX</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">n_comps</span><span class="p">)</span>
    <span class="n">v</span><span class="o">=</span><span class="n">scipy</span><span class="p">.</span><span class="n">sparse</span><span class="p">.</span><span class="nf">csr_matrix</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    


    <span class="c1">############ 
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">outputing V and U:</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">w</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">weights</span><span class="p">)).</span><span class="n">T</span><span class="p">)</span>
    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_column_scale</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">sparsefuncs</span><span class="p">.</span><span class="nf">inplace_row_scale</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

    
    <span class="n">gc</span><span class="p">.</span><span class="nf">collect</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">v</span><span class="p">.</span><span class="nf">todense</span><span class="p">().</span><span class="n">T</span><span class="p">),</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

</code></pre></div></div> <p>An ideal weights array would sum up to 1, and a cell‚Äôs weight must be inversely proportional to its population ‚Äòsize.</p> <p>For example, if a Batch of anndata is stored in .obs.Batch_key, we can get the frequency by:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">freq</span><span class="o">=</span> <span class="n">anndata</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">Batch_key</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">().</span><span class="nf">rename</span><span class="p">({</span><span class="sh">"</span><span class="s">index</span><span class="sh">"</span><span class="p">:</span><span class="n">Batch_key</span><span class="p">,</span><span class="n">Batch_key</span><span class="p">:</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">},</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">freq</span><span class="p">[</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">]</span><span class="o">=</span><span class="n">freq</span><span class="p">[</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">freq</span><span class="p">[</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">])</span>
<span class="n">freq</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">dt</span><span class="p">.</span><span class="n">obs</span><span class="p">[[</span><span class="n">Batch_key</span><span class="p">]],</span><span class="n">freq</span><span class="p">,</span><span class="n">how</span><span class="o">=</span><span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="n">Batch_key</span><span class="p">)</span>
</code></pre></div></div> <p>now we want the weights to be the inverse and normalizing these so they sum up to 1:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">w</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">freq</span><span class="p">[</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">]</span>
<span class="n">w</span><span class="o">=</span><span class="n">w</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</code></pre></div></div> <p>This can make a nice helper function:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_weights</span><span class="p">(</span><span class="n">anndata</span><span class="p">,</span><span class="n">Batch_key</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">Batch_key</span> <span class="ow">in</span> <span class="n">anndata</span><span class="p">.</span><span class="n">obs</span><span class="p">.</span><span class="n">columns</span>
    <span class="n">freq</span><span class="o">=</span> <span class="n">anndata</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">Batch_key</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">().</span><span class="nf">rename</span><span class="p">({</span><span class="sh">"</span><span class="s">index</span><span class="sh">"</span><span class="p">:</span><span class="n">Batch_key</span><span class="p">,</span><span class="n">Batch_key</span><span class="p">:</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">},</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">freq</span><span class="p">[</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">]</span><span class="o">=</span><span class="n">freq</span><span class="p">[</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">freq</span><span class="p">[</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">])</span>
    <span class="n">freq</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">dt</span><span class="p">.</span><span class="n">obs</span><span class="p">[[</span><span class="n">Batch_key</span><span class="p">]],</span><span class="n">freq</span><span class="p">,</span><span class="n">how</span><span class="o">=</span><span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="n">Batch_key</span><span class="p">)</span>
    <span class="n">w</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">freq</span><span class="p">[</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">w</span><span class="o">=</span><span class="n">w</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="nf">return</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</code></pre></div></div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2023 Hoang (Anh) Tran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1W7V2Y0MXW"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1W7V2Y0MXW");</script> <script async src="https://rum.cronitor.io/script.js"></script> <script>window.cronitor=window.cronitor||function(){(window.cronitor.q=window.cronitor.q||[]).push(arguments)},cronitor("config",{clientKey:""});</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>